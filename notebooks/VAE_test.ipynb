{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-based profiles VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from cytotraj.utils.model_utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building VAE class for Image-based profiles and Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProfileVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    VAE architecture for Image-based profiles\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        \"\"\"Initialize the Variational Autoencoder (VAE).\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            The number of input features (dimensions) in the data.\n",
    "        latent_dim : int\n",
    "            The dimension of the latent space.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(ImageProfileVAE, self).__init__()\n",
    "\n",
    "        # building the enconder sequence\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # define the layers responsible for mapping the output of the encoder neural network\n",
    "        self.fc_mean = nn.Linear(32, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(32, latent_dim)\n",
    "\n",
    "        # building the decoder sequence\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # methods for the VAE\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encode the input data into the latent space.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input data.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        mean : torch.Tensor\n",
    "            Mean of the latent space.\n",
    "        logvar : torch.Tensor\n",
    "            Logarithm of the variance of the latent space.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        mean = self.fc_mean(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Reparameterize the latent space for sampling.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        mean : torch.Tensor\n",
    "            Mean of the latent space.\n",
    "        logvar : torch.Tensor\n",
    "            Logarithm of the variance of the latent space.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        z : torch.Tensor\n",
    "            Sampled latent vector.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mean + epsilon * std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode the latent vector back into data space.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        z : torch.Tensor\n",
    "            Latent vector.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        x_recon : torch.Tensor\n",
    "            Reconstructed data.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the VAE.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input data.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        x_recon : torch.Tensor\n",
    "            Reconstructed data.\n",
    "        mean : torch.Tensor\n",
    "            Mean of the latent space.\n",
    "        logvar : torch.Tensor\n",
    "            Logarithm of the variance of the latent space.\n",
    "        \"\"\"\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mean, logvar\n",
    "\n",
    "\n",
    "# loss function\n",
    "def vae_loss(\n",
    "    x: np.ndarray, x_recon: np.ndarray, mean: np.ndarray, logvar: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the loss for a Variational Autoencoder (VAE) model.\n",
    "\n",
    "    This function computes the VAE loss, which comprises two main components:\n",
    "    - Reconstruction loss: It quantifies the dissimilarity between the input\n",
    "    data and its reconstructed version.\n",
    "    - KL divergence loss: This loss measures the divergence between the\n",
    "    learned latent space and a standard Gaussian distribution.\n",
    "\n",
    "    Parameters:\n",
    "    x : np.ndarray\n",
    "        The input data.\n",
    "    x_recon : np.ndarray\n",
    "        The reconstructed data.\n",
    "    mean : np.ndarray\n",
    "        The mean of the learned latent space.\n",
    "    logvar : np.ndarray\n",
    "        The log-variance of the learned latent space.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The total VAE loss, which is the summation of the reconstruction loss and\n",
    "        the KL divergence loss.\n",
    "    \"\"\"\n",
    "    # MSE (Reconstruction loss)\n",
    "    recon_loss = nn.functional.mse_loss(x_recon, x, reduction=\"sum\")\n",
    "\n",
    "    # KL divergence eq.\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    # total loss\n",
    "    return recon_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CustomData class for VAE's\n",
    "\n",
    "The `CustomDataset` class is designed to facilitate the integration of Pandas DataFrames with PyTorch for deep learning tasks.\n",
    "It converts the data from a Pandas DataFrame into a PyTorch Tensor with the appropriate data type, allowing for efficient usage in PyTorch data loaders.\n",
    "The class includes methods for determining the dataset's length and retrieving data samples by index, making it suitable for structured data applications.\n",
    "A typical use case is to create a `CustomDataset` instance from a Pandas DataFrame, enabling data loading for training and inference in PyTorch deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProfileDataset(Dataset):\n",
    "    \"\"\"A custom dataset class for working with PyTorch and Pandas DataFrames.\n",
    "\n",
    "    This class allows you to create a PyTorch Dataset from a Pandas DataFrame.\n",
    "    It's designed to provide an easy way to load and use your data in PyTorch's\n",
    "    data loading utilities.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        A Pandas DataFrame containing your data.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    data : torch.Tensor\n",
    "        The data from the DataFrame, converted to a PyTorch Tensor with dtype float32.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    __len__()\n",
    "        Get the number of samples in the dataset.\n",
    "\n",
    "    __getitem__(idx)\n",
    "        Retrieve a sample from the dataset by its index.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    df = pd.read_csv('your_data.csv')\n",
    "    dataset = CustomDataset(df)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        \"\"\"Initialize the CustomDataset with the provided data.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            A Pandas DataFrame containing your data.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        int\n",
    "            The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieve a sample from the dataset by its index.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        idx : int\n",
    "            The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The data sample as a PyTorch Tensor.\n",
    "        \"\"\"\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CFReT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_profile = pd.read_parquet(\n",
    "    \"./localhost220512140003_KK22-05-198_sc_normalized.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing features that do not contain real numerical values\n",
      "columns removed ['Metadata_WellRow', 'Metadata_treatment', 'Metadata_dose', 'Metadata_Plate', 'Metadata_Well', 'Metadata_Site']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making all values into float32 and drop NaN's\n"
     ]
    }
   ],
   "source": [
    "print(\"removing features that do not contain real numerical values\")\n",
    "object_columns = sc_profile.select_dtypes(include=[\"object\"])\n",
    "print(f\"columns removed {list(object_columns)}\")\n",
    "sc_profile = sc_profile.drop(columns=object_columns.columns)\n",
    "\n",
    "# making all values into float32\n",
    "print(\"making all values into float32 and drop NaN's\")\n",
    "sc_profile = sc_profile.astype(\"float32\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38876 entries, 0 to 43203\n",
      "Columns: 2015 entries, Metadata_WellCol to Nuclei_Texture_Variance_PM_3_03_256\n",
      "dtypes: float32(2015)\n",
      "memory usage: 299.1 MB\n"
     ]
    }
   ],
   "source": [
    "sc_profile.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE with CFReT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "input_dim = len(sc_profile.columns)\n",
    "latent_dim = 10\n",
    "batch_size = 64\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dataframe into Dataset class allowing easy integration to VAE\n",
    "dataloader = load_data(sc_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VAE and optimizer\n",
    "vae = ImageProfileVAE(input_dim, latent_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 30645740.0000\n",
      "Epoch [2/5], Loss: 28636526.0000\n",
      "Epoch [3/5], Loss: 36545096.0000\n",
      "Epoch [4/5], Loss: 28431962.0000\n",
      "Epoch [5/5], Loss: 27330366.0000\n"
     ]
    }
   ],
   "source": [
    "# training oop\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x = data\n",
    "        x_recon, mean, logvar = vae(x)\n",
    "        loss = vae_loss(x, x_recon, mean, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
